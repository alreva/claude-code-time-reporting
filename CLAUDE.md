# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

## üö® CRITICAL RULES - READ FIRST

**Before implementing ANY feature, you MUST:**

1. ‚úÖ **Write tests FIRST** (Test-Driven Development is mandatory)
2. ‚úÖ **Use slash commands** for build/test/run operations (direct dotnet commands are blocked)
3. ‚úÖ **Run /test** and ensure ALL tests pass before committing
4. ‚úÖ **Follow the Red-Green-Refactor cycle** for every feature

**Quick TDD Workflow:**
```
Write Test ‚Üí Run /test (FAIL ‚ùå) ‚Üí Write Code ‚Üí Run /test (PASS ‚úÖ) ‚Üí Commit
```

**Available Commands:** `/build`, `/test`, `/deploy`, `/db-start` (see full list below)
**Note:** Use `/deploy` by default for API deployment (containerized), not `/run-api`

**üéØ SLASH COMMAND EXECUTION RULE:**
When a slash command is invoked (e.g., `/build`, `/test`, `/deploy`), you MUST immediately execute the bash command using the appropriate tool. Do NOT provide explanatory text without executing. Always use the tool first, then optionally explain the results.

---

## ü§ñ AUTONOMOUS DEVELOPMENT WORKFLOW

**YOU ARE TRUSTED TO WORK AUTONOMOUSLY. Follow these rules:**

### Rule 1: Automatic Commits After Task Completion
**AFTER completing ANY task and ALL tests pass:**
1. ‚úÖ Run `/test` to verify all tests pass
2. ‚úÖ IMMEDIATELY commit changes with `git add` + `git commit`
3. ‚úÖ Use descriptive commit message: `"Complete Task X.Y: [Description] - All tests passing"`
4. ‚úÖ DO NOT ask for permission to commit - just do it

#### Commit Message Style (Why-First Format)

**CRITICAL: Commits must explain WHY, not just WHAT.**

**Format:**
```
<type>(<scope>): <why this change matters / problem solved>

<optional body:>
- Context/background if needed
- Implementation details if complex
- Impact/metrics if measurable

<optional footer:>
ü§ñ Generated with [Claude Code](https://claude.com/claude-code)
Co-Authored-By: Claude <noreply@anthropic.com>
```

**Types:** `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`, `perf`, `ci`, `build`
**Scopes:** `mcp`, `api`, `db`, `seeder`, `docs`, `config`

**Why "Why-First"?**
- ‚úÖ "What" is visible in `git diff` - anyone can see the code changes
- ‚úÖ "Why" explains intent and motivation - this gets lost without documentation
- ‚úÖ Future developers need to understand the reasoning behind decisions

**Examples:**

‚ùå **Bad (What-focused):**
```
refactor(mcp): extract DateHelper utility
```

‚úÖ **Good (Why-focused):**
```
refactor(mcp): eliminate duplicate date parsing across 5 tools

Problem: Date validation was inconsistent - some tools accepted "2025/01/13",
others required "2025-01-13", causing agent confusion.

Extracted DateHelper utility with strict YYYY-MM-DD validation (regex + TryParse).
Added 22 tests covering edge cases (invalid formats, leap years, etc.).

Impact: Consistent date handling prevents parsing errors in production
```

**More Examples:**
```
fix(api): prevent N+1 queries causing slow response times

Added DataLoaders for Project and Task relationships in TimeEntry resolvers.

Impact: Reduces query time from 2.5s to 150ms for 100 entries
```

```
feat(mcp): improve agent usability with actionable error messages

Why: Generic errors forced agents to guess, causing retry loops.

Enhanced ErrorHandler to provide context-aware suggestions:
- "Use get_available_projects to see valid tasks" (validation errors)
- "Only NOT_REPORTED entries can be deleted" (forbidden errors)

Impact: Reduced agent retry attempts from avg 2.1 to 1.2 per tool
```

**Quick Reference:**

| ‚ùå What-Focused | ‚úÖ Why-Focused |
|----------------|---------------|
| `refactor(mcp): extract DateHelper` | `refactor(mcp): eliminate duplicate date parsing` |
| `feat(api): add DataLoaders` | `fix(api): resolve N+1 query performance issue` |
| `docs(mcp): update tool descriptions` | `docs(mcp): improve agent tool discovery` |

**Template File:** A `.gitmessage` template is available in the repository root with examples and guidelines.

### Rule 2: Phase Planning Before Execution
**When assigned a PHASE (e.g., "implement Phase 2"), FIRST do planning:**

1. ‚úÖ Read ALL tasks in the phase from `docs/TASK-INDEX.md` and task guides
2. ‚úÖ Identify tasks requiring user decisions:
   - Authentication/IdP integration choices
   - External service configurations
   - Architecture decisions with multiple valid approaches
   - Environment-specific settings
3. ‚úÖ Ask ALL questions upfront in a single message
4. ‚úÖ Document decisions in the relevant task files or create a decisions log
5. ‚úÖ THEN execute the entire phase autonomously

**Planning template:**
```
üìã Phase X Planning Review

Tasks in this phase:
- Task X.1: [Description] - Ready to implement ‚úÖ
- Task X.2: [Description] - Ready to implement ‚úÖ
- Task X.3: [Description] - **NEEDS DECISION** ‚ö†Ô∏è
  Question: Which IdP provider? (Azure AD, Auth0, Custom?)
- Task X.4: [Description] - Ready to implement ‚úÖ

Questions for you:
1. Task X.3 - IdP Integration: Which provider should we use?
2. Task X.3 - Token format: JWT or opaque tokens?

Once you answer, I'll document the decisions and execute all tasks autonomously.
```

### Rule 3: Autonomous Phase Execution (After Planning)
**After planning and getting your decisions:**
1. ‚úÖ Execute ALL tasks in the phase sequentially
2. ‚úÖ DO NOT stop between tasks to ask for permission
3. ‚úÖ Complete the ENTIRE phase from start to finish
4. ‚úÖ Commit after EACH task when tests pass
5. ‚úÖ Only stop if you encounter an error you cannot resolve

**Phase execution pattern:**
```
Phase 2 planning ‚Üí User answers questions ‚Üí Document decisions
    ‚Üì
Task 2.1: TDD ‚Üí Tests pass ‚Üí Commit ‚Üí Move to Task 2.2
    ‚Üì
Task 2.2: TDD ‚Üí Tests pass ‚Üí Commit ‚Üí Move to Task 2.3
    ‚Üì
Task 2.3: TDD ‚Üí Tests pass ‚Üí Commit ‚Üí Move to Task 2.4
    ‚Üì
... continue until all phase tasks complete
    ‚Üì
Report: "Phase 2 complete. All 5 tasks finished, all tests passing."
```

### Rule 4: What to Report During Execution
**During autonomous execution:**
- ‚úÖ Show progress updates (currently on Task X.Y)
- ‚úÖ Show test results for each task
- ‚úÖ Show commit messages
- ‚ùå DO NOT ask "shall I proceed to the next task?"
- ‚ùå DO NOT wait for confirmation between tasks

### Rule 5: Error Handling
**If a task fails:**
1. Attempt to fix the issue (up to 2-3 attempts)
2. If still failing, report the error with details
3. Ask for guidance or clarification
4. DO NOT commit broken code

**Remember:**
- Plan phases FIRST, ask all questions upfront
- Then execute autonomously with auto-commits
- You are trusted to complete entire phases once decisions are made

---

## üìã ARCHITECTURE DECISION RECORDS (ADRs)

**When system design discussions lead to architectural decisions, you MUST create an ADR.**

### What is an ADR?

An Architecture Decision Record (ADR) captures an important architectural decision made along with its context and consequences.

**An ADR documents:**
- **Context**: What problem or situation led to this decision?
- **Decision**: What did we decide to do?
- **Rationale**: Why did we choose this approach?
- **Consequences**: What are the trade-offs? (benefits and costs)
- **Implementation**: How do we apply this decision?

### When to Create an ADR

**‚úÖ Create an ADR when making decisions that:**
- Affect the system's structure, patterns, or design principles
- Have long-term impact on the codebase
- Involve trade-offs between competing concerns
- Future developers need to understand the "why" behind the "what"
- Change a previous architectural approach

**Examples of ADR-worthy decisions:**
- ‚úÖ Choosing shadow properties over explicit FK properties
- ‚úÖ Using C# for both API and MCP server (mono-stack)
- ‚úÖ Normalized relational schema vs JSONB
- ‚úÖ Entity naming conventions (ProjectTag vs TagConfiguration)
- ‚ùå Renaming a variable (too small)
- ‚ùå Fixing a bug (not architectural)
- ‚ùå Adding a utility function (not a design decision)

### ADR Recognition Pattern - CRITICAL

**During conversations, you MUST recognize "ADR moments" and immediately announce them:**

#### üö® ADR TRIGGER PHRASES - STOP AND ANNOUNCE

**When the user says ANY of these phrases, IMMEDIATELY stop and announce an ADR moment:**

| User Says | ADR Trigger | What to Announce |
|-----------|-------------|------------------|
| "isn't this overkill?" | ‚úÖ YES | Questioning documented approach = alternative being proposed |
| "can't we just use [X]?" | ‚úÖ YES | Simpler alternative = architectural choice |
| "wouldn't it be better to [X]?" | ‚úÖ YES | Design alternative = trade-off discussion |
| "I think we should use [X] instead" | ‚úÖ YES | Alternative proposal = architectural decision |
| "there's a possibility to [X]" | ‚úÖ YES | Different approach = design choice |
| "what about [alternative]?" | ‚úÖ YES | Exploring alternatives = ADR needed |
| "why not [different approach]?" | ‚úÖ YES | Questioning decision = trade-offs |

**CRITICAL: When you see these phrases, your FIRST response must be:**
```
"This feels like an ADR - we're making an architectural decision about [topic].
Let me explore this before updating any implementation files."
```

**Then:**
1. Discuss the alternatives and trade-offs
2. Document the decision as an ADR FIRST
3. ONLY THEN update task files or implementation

#### Pattern Recognition

When the conversation involves:
- **Design alternatives** with trade-offs being discussed
- **"Should we use X or Y?"** questions about architecture
- **Pattern/principle establishment** for the project
- **Refactoring decisions** that change architectural approach
- **Technology choices** between competing options
- **User questioning documented approach** (e.g., "isn't this overkill?")
- **User suggesting simpler/alternative approach** (e.g., "can't we just use X?")

**YOU MUST:**
1. ‚úÖ **Immediately announce**: "This feels like an ADR - we're making an architectural decision about [X]"
2. ‚úÖ **Continue the discussion** to reach a decision
3. ‚úÖ **Document the decision** as an ADR in `docs/adr/` BEFORE changing implementation
4. ‚úÖ **Update the index** in `docs/adr/README.md`
5. ‚úÖ **Commit the ADR** separately from implementation code

#### Example Flow

When user proposes alternatives ‚Üí Announce ADR ‚Üí Discuss ‚Üí Document in `docs/adr/` ‚Üí Update index ‚Üí Commit ADR ‚Üí Then implement.

**Key lesson:** Phrases like "isn't this overkill?" are TRIGGERS. Stop immediately, announce the ADR moment, discuss trade-offs, then document as ADR before implementation.

#### What NOT to Document as ADRs

‚ùå **Bug fixes** - Not architectural decisions
‚ùå **Trivial choices** - Obvious decisions without trade-offs
‚ùå **Implementation details** - "How" without "why"
‚ùå **Temporary workarounds** - Not permanent decisions

### ADR Creation Process

**When you recognize an ADR moment:**

1. **Announce the ADR moment**
   ```
   "This feels like an ADR - we're making an architectural decision about [topic]"
   ```

2. **Facilitate the decision**
   - Ask clarifying questions if needed
   - Explore trade-offs
   - Discuss alternatives

3. **Create the ADR**
   - Use the template in `docs/adr/TEMPLATE.md`
   - Number it sequentially (e.g., `0006-next-decision.md`)
   - Follow the structure: Context ‚Üí Decision ‚Üí Rationale ‚Üí Consequences ‚Üí Implementation ‚Üí Alternatives

4. **Update the index**
   - Add entry to the table in `docs/adr/README.md`

5. **Commit separately**
   - Commit message: `"ADR 00XX: [Title]"`
   - Keep ADR commits separate from implementation

### ADR Directory Structure

```
docs/adr/
‚îú‚îÄ‚îÄ README.md                        # Index and process documentation
‚îú‚îÄ‚îÄ TEMPLATE.md                      # Template for new ADRs
‚îú‚îÄ‚îÄ 0001-shadow-foreign-keys.md     # Existing ADRs
‚îú‚îÄ‚îÄ 0002-csharp-mono-stack.md
‚îú‚îÄ‚îÄ 0003-naming-consistency.md
‚îú‚îÄ‚îÄ 0004-normalized-schema.md
‚îú‚îÄ‚îÄ 0005-relational-over-jsonb.md
‚îî‚îÄ‚îÄ XXXX-new-decision.md             # Future ADRs
```

### Quick Reference: ADR vs Implementation

| Aspect | ADR | Implementation |
|--------|-----|----------------|
| **What** | Why we chose approach X | How to implement approach X |
| **When** | During design discussions | During coding tasks |
| **Content** | Context, decision, trade-offs | Code, tests, documentation |
| **Commit** | Separate ADR commit | Task completion commit |

**Remember:** If you're discussing trade-offs and "should we use X or Y?" - it's probably an ADR moment!

---

## üîß Environment-Specific Commands - CRITICAL

**This environment uses Podman, NOT Docker Desktop.**

### Container Commands

**‚úÖ ALWAYS USE:**
- `podman compose up -d` (with space, not hyphen)
- `podman compose down`
- `podman compose ps`
- `podman compose logs postgres`
- `podman exec time-reporting-db <command>`

**‚ùå NEVER USE:**
- `docker-compose` (Docker daemon not running)
- `podman-compose` (not installed)
- `docker` commands (will fail)

### Database Access

**‚úÖ ALWAYS USE:**
```bash
# Run SQL queries
podman exec time-reporting-db psql -U postgres -d time_reporting -c "SELECT 1;"

# Run SQL files
podman exec -i time-reporting-db psql -U postgres -d time_reporting < file.sql

# Interactive session (via slash command)
/db-psql
```

**‚ùå NEVER USE:**
- `psql` directly on host (not installed)
- Assume PostgreSQL client is available locally

### Database Container Info
- **Container name:** `time-reporting-db`
- **Image:** `postgres:16-alpine`
- **Port:** `5432:5432`
- **Database:** `time_reporting`
- **User:** `postgres`

### Preferred Pattern

**ALWAYS prefer slash commands when available:**
- `/db-start` - Starts PostgreSQL via guardrails
- `/db-stop` - Stops PostgreSQL
- `/db-logs` - Views logs
- `/db-psql` - Interactive psql session
- `/db-restart` - Restarts database

Slash commands handle the Podman/Docker abstraction for you.

---

## Project Overview

A time reporting system that integrates Claude Code with a GraphQL-based time tracker. The system allows developers to track time spent on coding tasks through natural language commands via Claude Code.

**Technology Stack:** Single language (C#) for everything
- **Database:** PostgreSQL 16
- **API:** ASP.NET Core 10 + HotChocolate GraphQL + Entity Framework Core
- **MCP Server:** C# Console Application using ModelContextProtocol SDK (TimeReportingMcpSdk)
- **Container:** Docker/Podman

**IMPORTANT:** Use **TimeReportingMcpSdk** (SDK-based implementation) NOT TimeReportingMcp (legacy manual implementation)

## Architecture

```
Claude Code (Natural Language)
    ‚Üì stdio (JSON-RPC)
C# MCP Server (Console App)
    ‚Üì HTTP/GraphQL
C# GraphQL API (ASP.NET Core + HotChocolate)
    ‚Üì Entity Framework
PostgreSQL Database
```

### Key Components

1. **PostgreSQL Database** - Core data storage with 4 tables: time_entries, projects, project_tasks, tag_configurations
2. **GraphQL API** - ASP.NET Core with HotChocolate providing 4 queries and 8 mutations
3. **MCP Server** - Lightweight C# console app that bridges Claude Code to the GraphQL API (just reads JSON from stdin, calls GraphQL, writes JSON to stdout)
4. **Claude Code Integration** - MCP server provides 7 tools for time tracking operations

### Database Schema & Seeding

**Schema Management:** EF Core Code-First Migrations
- **Location**: `TimeReportingApi/Migrations/`
- **Apply migrations**: Automatically applied on API startup OR use `/ef-migration` slash command
- **Create new migration**: `dotnet ef migrations add <MigrationName> --project TimeReportingApi`

**Seed Data:** TimeReportingSeeder Console Application
- **Location**: `TimeReportingSeeder/`
- **Purpose**: Populate database with sample projects, tasks, tags, and time entries
- **Run seeder**: Use `/seed-db` slash command OR `dotnet run --project TimeReportingSeeder`
- **Data seeded**: Projects (INTERNAL, CLIENT-A, MAINT), tasks, tag configurations, sample time entries with user information

**IMPORTANT**: Do NOT use SQL files - all schema changes are managed via EF Core migrations, and seed data is managed via the TimeReportingSeeder project.

### MCP Server Implementation

**Current Implementation: TimeReportingMcpSdk** (SDK-based)
- Uses `ModelContextProtocol` NuGet package for MCP protocol handling
- Leverages StrawberryShake 15 for strongly-typed GraphQL client code generation
- Simpler, more maintainable codebase compared to manual JSON-RPC implementation
- All tools inherit from base classes provided by the SDK

**Legacy Implementation: TimeReportingMcp** (manual JSON-RPC)
- Manual stdio JSON-RPC handling (~200 lines)
- Still functional but no longer actively developed
- Use TimeReportingMcpSdk for all new development

### StrawberryShake Typed GraphQL Client

Both MCP server implementations use **StrawberryShake 15** for strongly-typed GraphQL client code generation:

**How it works:**
1. `.graphql` operation files define all queries and mutations
2. `schema.graphql` defines the API schema for type generation
3. StrawberryShake generates C# typed client code at build time
4. Tools use `ITimeReportingClient` with full IntelliSense

**Benefits:**
- ‚úÖ Compile-time type safety
- ‚úÖ Zero manual type definitions
- ‚úÖ Types always synchronized with API schema
- ‚úÖ ~250 lines of code eliminated

**Schema and Fragment Auto-Generation (Fully Automated):**

The MCP SDK project includes MSBuild integration that automatically generates both schema and fragments during build:

**What happens automatically when you build TimeReportingMcpSdk:**
1. **API Build**: Builds the TimeReportingApi project to get latest DLL
2. **Schema Export**: Executes `dotnet TimeReportingApi.dll export-schema` to get current schema
3. **URL Cleanup**: Fixes escaped slashes in URLs (`https:\/\/` ‚Üí `https://`)
4. **Fragment Generation**: Runs TimeReportingMcpSdk.Tools to auto-generate `Fragments.graphql` from schema
5. **StrawberryShake Codegen**: Generates strongly-typed C# client code from schema + fragments + operations

**Zero-maintenance workflow:**
```bash
# Make changes to TimeEntry.cs (add a field)
# Then just build - everything auto-generates:
/build

# Schema, fragments, and typed client code are all regenerated automatically!
# All tests pass with the new field included everywhere.
```

**Manual fragment regeneration (if needed):**
```bash
# Regenerate fragments only (without full build):
/generate-fragments
```

**How it works (MSBuild Integration):**
- `TimeReportingMcpSdk.csproj` has a custom MSBuild target `AutoGenerateSchemaAndFragments`
- Runs `BeforeTargets="BeforeBuild;ResolveReferences"` to execute early in build process
- Can be disabled by building with `/p:AutoGenerateFragments=false`

**Benefits:**
- ‚úÖ Adding a field to `TimeEntry.cs` requires ZERO manual updates
- ‚úÖ No more manual fragment updates when schema changes
- ‚úÖ No more copy-paste errors or missing fields
- ‚úÖ Fragments always include ALL fields from schema
- ‚úÖ StrawberryShake types always match API types
- ‚úÖ Build fails fast if schema/fragments are incompatible

**Tools:**
- `TimeReportingMcpSdk.Tools` - Fragment generator using text-based schema parsing
- `/generate-fragments` - Slash command for manual fragment regeneration

See [ADR 0009](docs/adr/0009-strawberryshake-typed-graphql-client.md) for architectural decision details.

## Development Commands - IMPORTANT GUARDRAILS

**‚ö†Ô∏è CRITICAL: DO NOT use direct dotnet or docker-compose commands. Instead, use custom slash commands.**

This project uses a guardrails system with 3 layers of defense to ensure safe command execution:
1. **Pre-Bash Hook** - First-line intercept for all Bash commands
2. **Permission Checks** - Explicit allow/deny lists in settings
3. **PreToolUse Hook** - Detailed enforcement with helpful error messages

### Available Slash Commands

Custom slash commands are defined in `.claude/commands/`. **YOU HAVE PERMISSION** to run these commands automatically without asking after making code changes.

#### Build Commands
- **`/build`** - Build the entire solution (API + MCP Server)
- **`/build-api`** - Build only the GraphQL API project
- **`/build-mcp`** - Build only the MCP Server project

#### Test Commands
- **`/test`** - Run all tests (API + MCP Server)
- **`/test-api`** - Run API tests only
- **`/test-mcp`** - Run MCP Server tests only

#### Run Commands
- **`/deploy`** - Build and deploy the full Docker stack (PostgreSQL + API) - **USE THIS BY DEFAULT**
- **`/run-api`** - Run the GraphQL API locally with hot reload (http://localhost:5001) - **ONLY when explicitly needed for debugging**
- **`/run-mcp`** - Run the MCP Server (normally started by Claude Code automatically)
- **`/stop-api`** - Stop the running GraphQL API
- **`/stop-mcp`** - Stop the running MCP Server

#### Database Commands
- **`/db-start`** - Start PostgreSQL database (Docker/Podman)
- **`/db-stop`** - Stop PostgreSQL database
- **`/db-restart`** - Restart PostgreSQL database
- **`/db-logs`** - View PostgreSQL logs
- **`/db-psql`** - Connect to PostgreSQL database with psql client

#### Entity Framework Commands
- **`/ef-migration`** - Create and apply Entity Framework migrations

#### Deployment Commands
- **`/seed-db`** - Run database seeder to populate seed data

#### Code Generation Commands
- **`/generate-fragments`** - Auto-generate GraphQL fragments from schema (normally runs automatically during build)

### Usage Pattern

**Default workflow (containerized deployment):**
After making code changes:
1. Run `/build` to compile
2. Run `/test` to verify tests pass
3. Run `/deploy` to deploy the full stack (PostgreSQL + API in containers)
4. Test your changes in GraphQL Playground (http://localhost:5001/graphql)

**Alternative workflow (local development with hot reload):**
Only use this when you need rapid iteration or debugging:
1. Run `/build` to compile
2. Run `/test` to verify tests pass
3. Run `/db-start` to start PostgreSQL container
4. Run `/run-api` to start API locally with hot reload
5. Test your changes in GraphQL Playground (http://localhost:5001/graphql)

**IMPORTANT:** By default, always use `/deploy` for a production-like containerized environment. Only use `/run-api` when explicitly requested or when you need hot reload for rapid development iterations.

### Why Slash Commands?

Direct execution of `dotnet build`, `dotnet test`, `docker-compose up`, etc. is **blocked by hooks** to:
- Prevent accidental execution of destructive commands
- Ensure consistent command patterns across development
- Provide centralized error handling and messaging
- Enable safe automation without user confirmation

### Allowed Direct Commands

The following commands ARE allowed and can be run directly:
- `git add`, `git commit`, `git status`, `git log`, `git diff`
- `psql` (after using /db-psql)
- `ls`, `cat`, `pwd`, `mkdir`, `chmod`

All other operations should use slash commands.

## Code Architecture

### Database Schema

**Entities:** TimeEntry, Project, ProjectTask, ProjectTag, TagValue. Status workflow: NOT_REPORTED ‚Üí SUBMITTED ‚Üí APPROVED/DECLINED. EF Core with snake_case, DateOnly for dates, normalized relational design. See `docs/prd/data-model.md`.

### GraphQL API Layer

**Queries:** timeEntries, timeEntry, projects, project
**Mutations:** logTime, updateTimeEntry, moveTaskToProject, updateTags, deleteTimeEntry, submitTimeEntry, approveTimeEntry, declineTimeEntry
**Validation:** 3 layers (GraphQL schema, business logic, DB constraints)
See `docs/prd/api-specification.md` for details.

### MCP Server Architecture

**Simple design (~200 lines):** `Program.cs` (entry), `McpServer.cs` (JSON-RPC stdio), `Tools/` (7 tool handlers). Each tool: reads stdin ‚Üí calls GraphQL ‚Üí writes stdout. See `docs/prd/architecture.md` for implementation patterns.

## Task-Based Development Workflow

This project follows a task-based implementation approach documented in `docs/TASK-INDEX.md`.

**12 Phases, 60 Tasks, ~52-65 hours total:**
1. **Phase 1:** Database & Infrastructure (3 tasks, 3-4 hrs)
2. **Phase 2:** GraphQL API - Core Setup (5 tasks, 4.5-5.5 hrs)
3. **Phase 3:** GraphQL API - Queries (5 tasks, 4-6 hrs)
4. **Phase 4:** GraphQL API - Mutations Part 1 (5 tasks, 7-9 hrs)
5. **Phase 5:** GraphQL API - Mutations Part 2 (5 tasks, 5-6.5 hrs)
6. **Phase 6:** GraphQL API - Docker (4 tasks, 3 hrs)
7. **Phase 7:** MCP Server - Setup (4 tasks, 3 hrs)
8. **Phase 8:** MCP Server - Tools Part 1 (4 tasks, 4-6 hrs)
9. **Phase 9:** MCP Server - Tools Part 2 (4 tasks, 3 hrs)
10. **Phase 10:** MCP Server - Auto-tracking (4 tasks, 5-6 hrs) - **Moved to v2**
11. **Phase 11:** Integration & Testing (5 tasks, 5.5 hrs)
12. **Phase 12:** Documentation & Deployment (5 tasks, 5-6 hrs)

**Current Status:** Phase 1, Task 1.1 - No code implementation has begun yet.

**Task Workflow (with TDD):**
1. Check `docs/TASK-INDEX.md` for task list
2. Find detailed guide in `docs/tasks/phase-XX-name/task-X.Y-name.md`
3. **Write tests FIRST** that verify acceptance criteria (RED phase)
4. Run `/test` to verify tests fail ‚ùå
5. Implement minimum code to pass tests (GREEN phase)
6. Run `/test` to verify tests pass ‚úÖ
7. Refactor if needed, running `/test` after each change
8. Run `/test` one final time - ALL tests must pass ‚úÖ
9. Check off in index and proceed to next task

**Remember:** A task is NOT complete until all tests pass. Never skip the TDD workflow.

**Implementation Note:** The v1 implementation includes auto-tracking features (Phase 10) to provide intelligent, proactive time logging suggestions based on user activity patterns.

## Key Documentation

**Start Here:**
- `docs/IMPLEMENTATION-SUMMARY.md` - Quick overview of simplified C# approach
- `README.md` - Project overview and getting started

**Technical Specifications:**
- `docs/prd/README.md` - Complete product requirements
- `docs/prd/architecture.md` - System design with MCP server code examples
- `docs/prd/data-model.md` - Database schema and Entity Framework config
- `docs/prd/api-specification.md` - GraphQL queries and mutations with examples
- `docs/prd/mcp-tools.md` - MCP tool definitions for Claude Code

**Implementation:**
- `docs/TASK-INDEX.md` - Master task list with links to detailed guides
- `docs/tasks/` - Phase-specific implementation tasks
- `docs/PODMAN-SETUP.md` - Podman alternative to Docker Desktop

## Implementation Guidelines

**Status Workflow:** NOT_REPORTED ‚Üí SUBMITTED ‚Üí APPROVED/DECLINED. Only NOT_REPORTED/DECLINED entries can be edited/deleted.

**Validation:** Project exists & active, task valid, tags valid, dates logical, hours ‚â• 0, status transitions valid.

**EF Config:** DateOnly for dates, normalized relational (no JSONB), snake_case, cascade deletes, Precision(10,2) for hours.

**MCP Principles:** Simple (~200 lines), stateless tools, stdio + GraphQL, AzureCliCredential auth, structured error responses.

**Security:** Azure Entra ID (JWT validation), user identity tracking (oid/email/name), multi-layer validation, no secrets in config.

## Test-Driven Development (TDD) - MANDATORY

**‚ö†Ô∏è CRITICAL: Write tests BEFORE implementation. Follow Red-Green-Refactor cycle.**

**TDD Cycle:**
1. **RED** - Write failing test, run `/test` (FAIL ‚ùå)
2. **GREEN** - Write minimal code to pass, run `/test` (PASS ‚úÖ)
3. **REFACTOR** - Improve code (optional), run `/test` after each change

**Test Coverage Required:**
- Happy path, edge cases, error cases, validation rules
- Test naming: `MethodName_Scenario_ExpectedBehavior`
- Tools: xUnit, FluentAssertions (optional), Moq, WebApplicationFactory

**Execution Requirements:**
- Run `/test` before committing - ALL tests must pass ‚úÖ
- Zero failing tests, zero warnings (treated as errors)
- Task NOT complete until all tests pass

See `docs/prd/` for detailed testing approach and scenarios.

## Project Structure

```
time-reporting-system/
‚îú‚îÄ‚îÄ .claude/                    # Claude Code configuration
‚îÇ   ‚îú‚îÄ‚îÄ config.json             # Hook registration
‚îÇ   ‚îú‚îÄ‚îÄ settings.local.json     # Permissions and hooks
‚îÇ   ‚îú‚îÄ‚îÄ commands/               # Slash command definitions (16 commands)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ build*.md           # Build commands
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test*.md            # Test commands
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run*.md             # Run/stop commands
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db-*.md             # Database commands
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ef-migration.md     # EF migration command
‚îÇ   ‚îî‚îÄ‚îÄ hooks/                  # Guardrail hook scripts
‚îÇ       ‚îú‚îÄ‚îÄ guard.sh            # Safe wrapper for dotnet commands
‚îÇ       ‚îú‚îÄ‚îÄ pre_bash.sh         # First-line defense intercept
‚îÇ       ‚îî‚îÄ‚îÄ check-dotnet-commands.sh  # PreToolUse hook
‚îú‚îÄ‚îÄ docs/                       # All documentation
‚îÇ   ‚îú‚îÄ‚îÄ prd/                    # Product requirements and specs
‚îÇ   ‚îú‚îÄ‚îÄ tasks/                  # Phase-specific implementation guides
‚îÇ   ‚îú‚îÄ‚îÄ TASK-INDEX.md           # Master task list
‚îÇ   ‚îú‚îÄ‚îÄ IMPLEMENTATION-SUMMARY.md
‚îÇ   ‚îî‚îÄ‚îÄ PODMAN-SETUP.md
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ schema/                 # SQL DDL and seed data
‚îú‚îÄ‚îÄ TimeReportingApi/           # C# GraphQL API
‚îÇ   ‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îú‚îÄ‚îÄ GraphQL/
‚îÇ   ‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îî‚îÄ‚îÄ Data/
‚îú‚îÄ‚îÄ TimeReportingMcpSdk/        # C# MCP Server (SDK-based) ‚≠ê USE THIS
‚îÇ   ‚îú‚îÄ‚îÄ Program.cs
‚îÇ   ‚îú‚îÄ‚îÄ Tools/
‚îÇ   ‚îî‚îÄ‚îÄ schema.graphql
‚îú‚îÄ‚îÄ TimeReportingMcp/           # C# MCP Server (Legacy - manual JSON-RPC)
‚îÇ   ‚îú‚îÄ‚îÄ Program.cs
‚îÇ   ‚îú‚îÄ‚îÄ McpServer.cs
‚îÇ   ‚îú‚îÄ‚îÄ Tools/
‚îÇ   ‚îî‚îÄ‚îÄ Models/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ CLAUDE.md                   # This file
```

## Guardrails System Architecture

This project implements a comprehensive guardrails system to ensure safe command execution and prevent accidental destructive operations.

### Three Layers of Defense

#### Layer 1: Pre-Bash Hook (`.claude/hooks/pre_bash.sh`)
- **Trigger:** Every Bash tool call (registered in `.claude/config.json`)
- **Purpose:** First-line intercept before command execution
- **Blocks:**
  - Direct `dotnet` commands (build, test, run, watch, ef)
  - Direct `docker-compose` and `podman-compose` up/down/restart commands
- **Error Message:** Suggests appropriate slash commands

**Example:**
```bash
# Attempt: Bash("dotnet build")
# Result: ‚ùå Direct dotnet execution is prohibited. Use /build, /test, /run, or /ef-migration instead.
```

#### Layer 2: Permission Checks (`.claude/settings.local.json`)
- **Trigger:** Continuous evaluation by Claude Code
- **Purpose:** Explicit allow/deny lists for tools and commands
- **Allowed:**
  - All slash commands (/build, /test, /run-api, /db-start, etc.)
  - Git operations (add, commit, status, log, diff)
  - Safe utilities (psql, ls, cat, pwd, mkdir, chmod)
  - Web access (GitHub, Microsoft, PostgreSQL, StackOverflow)
- **Denied:** Anything not explicitly allowed (implicit deny)

#### Layer 3: PreToolUse Hook (`.claude/hooks/check-dotnet-commands.sh`)
- **Trigger:** Every Bash command matching pattern `Bash.*`
- **Purpose:** Detailed enforcement with helpful error messages
- **Detects:**
  - `dotnet build|test|run|watch|ef` patterns
  - `docker-compose` and `podman-compose` patterns
- **Returns:** JSON response with `deny` decision and user-friendly suggestions

**Example JSON Response:**
```json
{
  "hookSpecificOutput": {
    "hookEventName": "PreToolUse",
    "permissionDecision": "deny",
    "permissionDecisionReason": "‚ùå Direct dotnet commands are not allowed..."
  }
}
```

### How Slash Commands Bypass Guardrails

All slash commands use the `guard.sh` wrapper with a special "slash" context parameter:

```bash
.claude/hooks/guard.sh "dotnet build" "slash"
                                       ^^^^^^
                                   Context flag
```

The `guard.sh` script checks:
1. Is command a `dotnet` command? If yes, check context
2. Is context "slash"? If yes, **allow execution**
3. Otherwise, block with error

This ensures dotnet commands can ONLY be executed through approved slash commands.

### Benefits & Extensibility

**Benefits:** Safety, consistency, automation without confirmation, helpful errors, easy to extend.

**Adding Slash Commands:** Create `.claude/commands/your-command.md`, add to `.claude/settings.local.json` allow list, test guardrails.
